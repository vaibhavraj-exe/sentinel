{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8790/3387971672.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace({True: 1, False: 0}, inplace=True)\n",
      "/tmp/ipykernel_8790/3387971672.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace({'bot': 1, 'human': 0}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv ('dataset/clean_bot.csv')\n",
    "df.replace({True: 1, False: 0}, inplace=True)\n",
    "df.replace({'bot': 1, 'human': 0}, inplace=True)\n",
    "\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "# scaler = StandardScaler()\n",
    "# columns_to_standardize = ['favourites_count','followers_count','friends_count','average_tweets_per_day','account_age_days']\n",
    "# df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 0.0000e+00, 2.3700e+02, 2.7394e+04, 5.4200e+02,\n",
       "        0.0000e+00, 0.0000e+00, 8.4280e+00, 1.3660e+03, 1.0000e+00]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = df.loc[[5]].values\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "input = np.array([[1.0000e+00, 0.0000e+00, 2.3700e+02, 2.7394e+04, 5.4200e+02,\n",
    "        0.0000e+00, 0.0000e+00, 8.4280e+00, 1.3660e+03]])\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000e+00, 0.0000e+00, 2.3700e+02, 2.7394e+04, 5.4200e+02,\n",
       "       0.0000e+00, 0.0000e+00, 8.4280e+00, 1.3660e+03])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[5],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_input = X[5].reshape(1,-1)\n",
    "test_input = input\n",
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanley/miniconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = joblib.load('models/scaler.pkl')\n",
    "columns_to_standardize = [2,3,4,7,8]\n",
    "data_to_transform = test_input[:,columns_to_standardize]\n",
    "transformed_data = scaler.transform(data_to_transform)\n",
    "standardized_input = test_input.copy()\n",
    "standardized_input[:,columns_to_standardize] = transformed_data\n",
    "\n",
    "standardized_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33801169, 0.66198831]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = joblib.load(\"models/logistic_regression_model.pkl\")\n",
    "predictions = loaded_model.predict_proba(standardized_input)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regular': array([1.000e+00, 0.000e+00, 8.433e+03, 5.170e+02, 6.330e+02, 1.000e+00,\n",
       "        0.000e+00, 8.890e-01, 1.489e+03]),\n",
       " 'spam': array([1.0000e+00, 0.0000e+00, 2.3700e+02, 2.7394e+04, 5.4200e+02,\n",
       "        0.0000e+00, 0.0000e+00, 8.4280e+00, 1.3660e+03])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_test_input = {\n",
    "    \"features\": ['default_profile', 'default_profile_image', 'favourites_count', 'followers_count','friends_count',\t'geo_enabled','verified','average_tweets_per_day','account_age_days'],\n",
    "    \"regular\": [1.000e+00, 0.000e+00, 8.433e+03, 5.170e+02, 6.330e+02, 1.000e+00,\n",
    "        0.000e+00, 8.890e-01, 1.489e+03],\n",
    "    \"spam\": [1.0000e+00, 0.0000e+00, 2.3700e+02, 2.7394e+04, 5.4200e+02,\n",
    "        0.0000e+00, 0.0000e+00, 8.4280e+00, 1.3660e+03]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rows for\n",
    "\n",
    "spam_account = 5\n",
    "regular account = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3700e+02, 2.7394e+04, 5.4200e+02, 8.4280e+00, 1.3660e+03]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = np.array([1.0000e+00, 0.0000e+00, 2.3700e+02, 2.7394e+04, 5.4200e+02,\n",
    "        0.0000e+00, 0.0000e+00, 8.4280e+00, 1.3660e+03])\n",
    "input = np.array([input])\n",
    "input.shape\n",
    "data_to_transform = input[:,columns_to_standardize]\n",
    "data_to_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6619883051429746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanley/miniconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "scaler = joblib.load('models/scaler.pkl')\n",
    "model = joblib.load(\"models/logistic_regression_model.pkl\")\n",
    "columns_to_standardize = [2,3,4,7,8]\n",
    "input = np.array([1.0000e+00, 0.0000e+00, 2.3700e+02, 2.7394e+04, 5.4200e+02,\n",
    "        0.0000e+00, 0.0000e+00, 8.4280e+00, 1.3660e+03])\n",
    "\n",
    "def spam_forward(input):\n",
    "    input = np.array([input])\n",
    "    data_to_transform = input[:,columns_to_standardize]    \n",
    "    transformed_data = scaler.transform(data_to_transform)\n",
    "    standardized_input = input.copy()\n",
    "    standardized_input[:,columns_to_standardize] = transformed_data\n",
    "    \n",
    "    predictions = loaded_model.predict_proba(standardized_input)\n",
    "    spam_pred = predictions[0][1]\n",
    "    print(spam_pred)\n",
    "    \n",
    "spam_forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
